"""Utility functions for writing compliance logs and reports."""

from __future__ import annotations

import hashlib
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Optional

from .models import AuditLogEntry, SessionContext

LOGGER = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Compute a unique run hash at module import time to link all log lines
_RUN_HASH = hashlib.sha256(str(datetime.utcnow().timestamp()).encode()).hexdigest()[:8]

# Base directories relative to the repository
_BASE_DIR = Path(__file__).resolve().parents[1]
_LOG_DIR = _BASE_DIR / "logs"
_REPORT_DIR = _BASE_DIR / "reports"
_LOG_FILE = _LOG_DIR / "audit_log.jsonl"
_LOG_SIZE_LIMIT = 5 * 1024 * 1024  # 5 MB


# ---------------------------------------------------------------------------


def _rotate_logs() -> None:
    """Rotate the main audit log when it exceeds the configured size."""
    try:
        if _LOG_FILE.exists() and _LOG_FILE.stat().st_size >= _LOG_SIZE_LIMIT:
            index = 1
            while (_LOG_DIR / f"audit_log_{index}.jsonl").exists():
                index += 1
            dest = _LOG_DIR / f"audit_log_{index}.jsonl"
            _LOG_FILE.rename(dest)
            LOGGER.info("Rotated audit log to %s", dest)
    except Exception as exc:  # pragma: no cover - OS specific failures
        LOGGER.exception("Failed rotating logs: %s", exc)


# ---------------------------------------------------------------------------


def log_decision(
    log_entry: AuditLogEntry, session: Optional[SessionContext] = None
) -> None:
    """Append ``log_entry`` to ``audit_log.jsonl`` with run metadata.

    The function writes a single JSON object per line allowing efficient
    post-processing of compliance logs. A ``run_hash`` field groups all
    entries generated by the same invocation of the tooling. When the log
    grows beyond 5 MB it is automatically archived to
    ``audit_log_{N}.jsonl`` where ``N`` is an incrementing integer.

    Parameters
    ----------
    log_entry:
        Structured audit log entry describing an event.
    session:
        Optional session context to embed alongside the entry.
    """

    try:
        _LOG_DIR.mkdir(parents=True, exist_ok=True)
        _rotate_logs()

        record = log_entry.to_dict()
        record["run_hash"] = _RUN_HASH
        record["session_context"] = session.to_dict() if session else None
        record["timestamp"] = log_entry.timestamp.isoformat()

        with _LOG_FILE.open("a", encoding="utf-8") as fh:
            fh.write(json.dumps(record, default=str) + "\n")
        LOGGER.info("Logged decision for rule %s", log_entry.rule_id)
    except Exception as exc:  # pragma: no cover - unexpected filesystem issues
        LOGGER.exception("Failed to write audit log: %s", exc)


# ---------------------------------------------------------------------------


def log_session_report(entries: List[AuditLogEntry], file_path: str) -> None:
    """Generate a Markdown governance report from ``entries``.

    The resulting file documents rule identifiers, referenced clauses,
    chosen actions and associated risk scores in both YAML and table form
    for ease of manual review. The report is saved under ``file_path``,
    typically ``reports/iso_eu_mapping.md``.

    Parameters
    ----------
    entries:
        List of audit log entries from a single run or session.
    file_path:
        Destination Markdown file path relative or absolute.
    """

    try:
        path = Path(file_path)
        if not path.is_absolute():
            path = _REPORT_DIR / path
        path.parent.mkdir(parents=True, exist_ok=True)

        summary = [
            {
                "rule_id": e.rule_id,
                "clause": e.clause_id,
                "action": e.action,
                "risk_score": e.risk_score,
            }
            for e in entries
        ]

        yaml_block = json.dumps({"run_hash": _RUN_HASH, "entries": summary}, indent=2)

        table_lines = [
            "| rule_id | clause | action | risk_score |",
            "| --- | --- | --- | --- |",
        ]
        for s in summary:
            table_lines.append(
                f"| {s['rule_id']} | {s['clause'] or ''} | {s['action']} | {s['risk_score'] or ''} |"
            )
        table = "\n".join(table_lines)

        content = (
            f"# ISO/EU Governance Mapping\n\nGenerated: {datetime.utcnow().isoformat()} UTC\n\n"
            f"```yaml\n{yaml_block}\n```\n\n{table}\n"
        )
        path.write_text(content, encoding="utf-8")
        LOGGER.info("Wrote session report to %s", path)
    except Exception as exc:  # pragma: no cover - filesystem errors
        LOGGER.exception("Failed to write session report: %s", exc)
